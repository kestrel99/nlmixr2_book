# History {#history}

This book has been a long time in coming.

## In the beginning, there was `RxODE`

Our story begins with `RxODE`. `RxODE` was developed by Melissa Hallow and Wenping Wang as an R package for facilitating quick and efficient simulations of ODE models [@Wang2016]. Work first began in the equivalent of WEenping's garage in 2005, and when it was finally presented by Melissa Hallow at the PAGE meeting in Crete in 2015 [@Hallow2015], the idea was floated to use its machinery for parameter estimation using `nlme`, the R implementation of nonlinear mixed-effects models by Pinheiro and Bates [@Pinheiro2000]. As it turned out, work on developing this concept was already pretty advanced by that time, and parameter estimation with both `nlme` and stochastic annealing expectation maximization (SAEM) [@Delyon1999] was implemented by Wenping by the end of that year.

## Stan

The next milestone came at ACoP6 the same year, when Yuan Xiong first presented `PMXstan` [@Xiong2015]. Applying fully Bayesian approaches to pharmacometric modeling has always been a challenging task, and `PMXstan` was proposed as a way to bridge the gap. Stan [@carpenterStanProbabilisticProgramming2017] implements gradient-based Markov chain Monte Carlo (MCMC) algorithms for Bayesian inference, stochastic, gradient-based variational Bayesian methods for approximate Bayesian inference, and gradient-based optimization for penalized maximum likelihood estimation, and can easily be run from R. However, before `PMXstan`, pharmacometricians had to write their own Stan code to describe PKPD models, and preparing data files was arduous and counter-intuitive for those used to event-based data files like those used in NONMEM. Also, there were no efficient ODE solvers that could handle stiff systems that would work with its No-U-Turn Sampler (NUTS) [@homanNoUturnSamplerAdaptively2014]. `PMXstan` solved this by providing wrappers for the more unfriendly parts of the process, closed-form solutions for common PK systems written in Stan code, and a NUTS-compatible template LSODA solver to deal with stiff ODE systems. Significantly, these were components that would become quite important for a more general nonlinear mixed-effects (NLME) model fitting tool. (Since then, our colleagues at Metrum Research Group have taken things in all kinds of new and interesting directions with `Torsten`, a toolkit providing explicit pharmacometric functionality to Stan. But that, dear reader, is another story.)

## GitHub

The first `nlmixr` commit to GitHub was on 19 October 2016, and by then a small team had sprung up around the project, with Wenping Wang and Yuan Xiong at its core within Novartis, and a small group of interested parties including Teun Post and Richard Hooijmaaijers at LAP&P and Rik Schoemaker and Justin Wilkins at Occams.

In December 2016, `nlmixr` was presented to the modeling group at Uppsala University, where the implementation of the first-order conditional estimation method with interaction (FOCEI) by Almquist and colleagues [@Almquist2015] was first discussed.

## CRAN

Matt Fidler joined the team at Novartis in January 2017, and implemented the FOCEI method, bringing the number of available algorithms to three. June 2017 saw the introduction of a unified user interface across all three algorithms, a major milestone, and our first CRAN release was `nlmixr` 0.9.0-1 on 9 November 2017. An official 1.0 would follow in August 2018. By now the team had widened to include Mirjam Trame, who, together with Wenping, was using `nlmixr` as the core of a series of pharmacometric training courses in Cuba and elsewhere in Central and South America.

## First peer-reviewed publications

Although `nlmixr` had been a regular fixture at PAGE and ACoP in the intervening years, our first major publication would arrive in 2019, in the form of a tutorial introducing `nlmixr` to the wider pharmacometric world [@Fidler2019], and two months later, a comparison of algorithms between `nlmixr` and its gold standard commercial alternatives (FOCEI in NONMEM and SAEM in Monolix) followed [@Schoemaker2019].

## Streamlining and modularization

Installing `nlmixr` was, at this time, a complicated and daunting business, and although many in the pharmacometrics community had taken to `nlmixr` with enthusiasm, this was a large disadvantage that, to be frank, was turning people off. It had long been necessary to use Python for handling some aspects of FOCEI fitting, and getting it to work properly together with R was *hard*. This was further complicated by CRAN's very effective but very rigid package review and approval system, which was leading to endless problems with keeping the various dependencies `nlmixr` had in sync with one another. In April 2021, `nlmixr` 2.0 was unleashed upon the world, and Python was left behind forever. To say this was a relief to the development team was to understate the emotional catharsis that took place.

Although this solved one problem, another had been brewing. `nlmixr` had become a large package by R standards, and compile times at CRAN had begun to irk its administrators, leading to significant delays in approval. This eventually led to the decision to reimplement `nlmixr` as a series of closely linked, modular packages as opposed to a single monolithic unit. Rather than reverse-engineer the original `nlmixr`, the decision was taken to fork the project, and `nlmixr2` was born in February 2022. `nlmixr` would remain on GitHub, but would no longer be developed actively, while new features and ongoing improvements would be applied to `nlmixr2`. The first CRAN release of `nlmixr2` took place in June 2022.

Up to 26 March 2022, the date on which the last commit was made to the original version of `nlmixr`, there were 2,403 commits to the nlmixr repository and 17 more CRAN releases. `RxODE` had 4,860 commits and 33 CRAN releases (some before `nlmixr`'s time, but we're just going to go ahead and count them anyway).

Since then, we've seen encouraging interest and explosive growth. The development team has undergone seismic chnages - Wenping and Teun have moved on, while Matt has taken on the role of lead developer, supported (at the time of writing) by Bill Denney, John Harrold, Richard Hooijmaaijers, Anne Keunecke, Theo Papathanasiou, Rik Schoemaker, Max Taubert, Mirjam Trame, and Justin Wilkins. `nlmixr2` version 3.0 was released in late 2024, and a flurry of add-on packages, including [`babelmixr2`](https://nlmixr2.github.io/babelmixr2/), [`nonmem2rx`](https://nlmixr2.github.io/nonmem2rx/), [`monolix2rx`](https://nlmixr2.github.io/monolix2rx/), [`nlmixr2extra`](https://nlmixr2.github.io/nlmixr2extra/), [`nlmixr2rpt`](https://nlmixr2.github.io/nlmixr2rpt/) and [`nlmixr2lib`](https://nlmixr2.github.io/nlmixr2lib/) have been released.  

## Community enthusiasm

Over the years, we've hosted numerous tutorials at the major pharmacometrics meetings (PAGE, ACoP, PAGANZ and WCoP), and used `nlmixr` as the centrepoint for a series of well-received pharmacometrics courses in Cuba and elsewhere. We've also managed to publish a bit [@Fidler2021], as have others (we'll get into this later on).

Our tutorial in *Clinical Pharmacology & Therapeutics: Pharmacometrics & Systems Pharmacology* [@Fidler2019] was one of that journal's top ten most-read articles in 2021, with over 4,000 downloads. Our article had been one of the top 10% most-downloaded papers in 2018-2019, and having such interest for the second time in a row is tremendously encouraging for all of us! We hope it's a reflection of the enthusiasm the community is building for our tool, and hope that it will continue.

Academic groups have been using our tools with some success - University College London published recently on models for SARS-CoV-2 [@agyeman_comparative_2022] and metformin [@mak_assessment_2023], for example. 

Finally, several more R packages using nlmixr2 have been released, including [`posologyr`](https://levenc.github.io/posologyr/) and [`nlmixr2auto`](https://github.com/ucl-pharmacometrics/nlmixr2auto).  

## But why?

It's not about the money. Well, it is, but not in the way you think. It's safe to say that commercial gain is not a motivation for this project.

The money argument is twofold. Pharmacometrics is a small market, so developing commercial software in this space is very risky, and even if you succeed, any tool that is successfully developed will need to be very expensive to recoup one's investment, and there is always an indefinite commitment to support, which is a deceptively massive overhead. So it was clear right from the beginning that we were not going to go that way. On top of this, software licenses are a non-trivial operating cost, especially for smaller players like some of us, so there is a large incentive to find cheaper ways to do our work. But it wasn't completely this either, to be honest.

Starting out in pharmacometrics is challenging. It's a tough field, since it requires one to have a wide range of highly technical skills: pharmacology, math, statistics, computers, and so on. If you're sitting in a stuffy office in an underfunded university in a low-or-middle-income country 10,000 kilometres (literally) from the nearest pharmacometrics center of excellence, you have additional challenges. One: who is going to help you learn this stuff? Two: how are you going to afford the software tools you need? (Even at academic rates, NONMEM, Monolix and company are expensive, and hard to justify in a resource-poor environment when only a few students and staff are going to use it. Especially when hardware and power costs are also taken into account.) There was a crying need for an accessible, low-to-no cost tool to reduce this not-insignificant barrier to entry into our field.

So: Cost! Free software makes pharmacometric modelling (more) accessible in low to middle income countries. Not needing to buy a license makes preparing and giving courses much easier (many pharmacometrics courses are already using `nlmixr2`). Academic licenses might appear to solve this issue to an extent, but these usually cannot be used for commercial work making actual drug development in a low income environment difficult.

Curiosity! Can we make NLME parameter estimation work in R, where others have tried and failed? So far the answer seems to be yes.

Convenience! Having inputs, analyses and outputs in a single environment (R) is super attractive and makes workflows very efficient.

Creativity and collaboration! Whereas open science - of which we are massive fans, it should go without saying - allows one to 'stand on the shoulders of giants', adding open source to the mix allows everyone to take the software and run with it, developing applications we would never have thought of.

Finally: Concern! What will happen to NONMEM when its sole lead developer retires? Having a backup solution is very reassuring.

This book is the next step in our journey; thanks for taking it with us.
